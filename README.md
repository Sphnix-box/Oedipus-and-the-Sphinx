# Oedipus-and-the-Sphinx
Oedipus and the Sphinx: Benchmarking and Improving Visual Language Models for Complex Graphic Reasoning

Evaluating the performance of visual language models (VLMs) in graphic reasoning tasks has become an important research topic. However, VLMs still show obvious deficiencies in simulating human-level graphic reasoning capabilities, especially in complex graphic reasoning and abstract problem solving, which are less studied and existing studies only focus on simple graphics. To evaluate the performance of VLMs in complex graphic reasoning, we propose \textbf{ReasonBench}, the first evaluation benchmark focused on structured graphic reasoning tasks, which includes 1,613 questions from real-world intelligence tests. ReasonBench covers reasoning dimensions related to location, attribute, quantity, and multi-element tasks, providing a comprehensive evaluation of the performance of VLMs in spatial, relational, and abstract reasoning capabilities. We benchmark 11 mainstream VLMs (including closed-source and open-source models) and reveal significant limitations of current models. Based on these findings, we propose a dual optimization strategy: \textbf{Diagrammatic Reasoning Chain (DiaCoT)} enhances the interpretability of reasoning by decomposing layers, and \textbf{ReasonTune} enhances the task adaptability of model reasoning through training, all of which improves VLM performance by 33.5\%.

# After the review results, we will publish our dataset and code, including the URL and analysis of each image. Coming soon...
